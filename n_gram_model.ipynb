{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('tokenized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eliciting priors from experts</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what is normality ?</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what are some valuable statistical analysis op...</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assessing the significance of differences in d...</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the two cultures : statistics vs . machine lea...</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  parent_id  comment_id  \\\n",
       "0        1        NaN         NaN   \n",
       "1        2        NaN         NaN   \n",
       "2        3        NaN         NaN   \n",
       "3        4        NaN         NaN   \n",
       "4        6        NaN         NaN   \n",
       "\n",
       "                                                text category  \n",
       "0                      eliciting priors from experts    title  \n",
       "1                                what is normality ?    title  \n",
       "2  what are some valuable statistical analysis op...    title  \n",
       "3  assessing the significance of differences in d...    title  \n",
       "4  the two cultures : statistics vs . machine lea...    title  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[df.category=='title']\n",
    "train = df[df.category!='title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91736</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>how should i elicit prior distributions from e...</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91737</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in many different statistical methods there is...</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91738</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what are some valuable statistical analysis op...</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91739</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i have two groups of data . each with a differ...</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91740</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the r project r is valuable and significant be...</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810595</th>\n",
       "      <td>279994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536471.0</td>\n",
       "      <td>it does run , and gives very valid looking est...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810596</th>\n",
       "      <td>279998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536439.0</td>\n",
       "      <td>it seems to me that you are correct ; the doub...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810597</th>\n",
       "      <td>279998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536514.0</td>\n",
       "      <td>it would not be the first time a grader has mi...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810598</th>\n",
       "      <td>279999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536802.0</td>\n",
       "      <td>the basic idea is to compare the clustering co...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810599</th>\n",
       "      <td>279999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>542550.0</td>\n",
       "      <td>as per your other question , your data does no...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>718864 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        post_id  parent_id  comment_id  \\\n",
       "91736         1        NaN         NaN   \n",
       "91737         2        NaN         NaN   \n",
       "91738         3        NaN         NaN   \n",
       "91739         4        NaN         NaN   \n",
       "91740         5        3.0         NaN   \n",
       "...         ...        ...         ...   \n",
       "810595   279994        NaN    536471.0   \n",
       "810596   279998        NaN    536439.0   \n",
       "810597   279998        NaN    536514.0   \n",
       "810598   279999        NaN    536802.0   \n",
       "810599   279999        NaN    542550.0   \n",
       "\n",
       "                                                     text category  \n",
       "91736   how should i elicit prior distributions from e...     post  \n",
       "91737   in many different statistical methods there is...     post  \n",
       "91738   what are some valuable statistical analysis op...     post  \n",
       "91739   i have two groups of data . each with a differ...     post  \n",
       "91740   the r project r is valuable and significant be...     post  \n",
       "...                                                   ...      ...  \n",
       "810595  it does run , and gives very valid looking est...  comment  \n",
       "810596  it seems to me that you are correct ; the doub...  comment  \n",
       "810597  it would not be the first time a grader has mi...  comment  \n",
       "810598  the basic idea is to compare the clustering co...  comment  \n",
       "810599  as per your other question , your data does no...  comment  \n",
       "\n",
       "[718864 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefix-word matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how should i elicit prior distributions from experts when fitting a bayesian model ?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = train.text.values[0]\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('how', 'should', 'i'),\n",
       " ('should', 'i', 'elicit'),\n",
       " ('i', 'elicit', 'prior'),\n",
       " ('elicit', 'prior', 'distributions'),\n",
       " ('prior', 'distributions', 'from'),\n",
       " ('distributions', 'from', 'experts'),\n",
       " ('from', 'experts', 'when'),\n",
       " ('experts', 'when', 'fitting'),\n",
       " ('when', 'fitting', 'a'),\n",
       " ('fitting', 'a', 'bayesian'),\n",
       " ('a', 'bayesian', 'model'),\n",
       " ('bayesian', 'model', '?')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(line.split(), n=3, left_pad_symbol='<s>', right_pad_symbol='</s>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_matrix = defaultdict(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b1e7fa1f3f4f1da81eb233838f8d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=718864.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for text in tqdm(train.text):\n",
    "    for x in ngrams(text.split(), n=3, left_pad_symbol='<s>', right_pad_symbol='</s>'):\n",
    "        bigram, token = x[:-1], x[-1]\n",
    "        word_matrix[bigram][token] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_temp_sample(elems, probas, tau = 1.0):\n",
    "    probas = [p**(1.0/tau) for p in probas]\n",
    "    return random.choices(elems, probas)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(bigram, n=None):\n",
    "    first, second = bigram\n",
    "    result = [first, second]\n",
    "    while second != '</s>':\n",
    "        cnt = word_matrix[(first, second)]\n",
    "        if not cnt:\n",
    "            break\n",
    "        pairs = cnt.most_common()\n",
    "        words, probas = list(zip(*pairs))\n",
    "        token = make_temp_sample(words, probas, tau=1)\n",
    "        result.append(token)\n",
    "        first = second\n",
    "        second = token\n",
    "        if n is not None and len(result) == n:\n",
    "            break\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you see a more frequentist like approach ? or is there a better approach than psm . if you are trying to do more preprocessing after initial communalities as smc of p instead of evaluating how recoverable the solutions different ? or please define all possible types , so by the intercept : or produce , so in a more sophisticated hampel filter . so i only got half of a dense representation from a bayesian approach or at least pages long . given the value of x values , i do not see why , please elaborate a little'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(('you', 'see'), n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = len({token for text in train.text for token in text.split()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_trigram_proba(trigram, delta=1.0):\n",
    "    bigram = trigram[:-1]\n",
    "    token = trigram[-1]\n",
    "    freqs = word_matrix.get(bigram, {})\n",
    "    count_tok = freqs.get(token, 0)\n",
    "    count_pref = sum(freqs.values())\n",
    "    p = (count_tok + delta) / (count_pref + delta * VOCABULARY_SIZE)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_text_proba(text):\n",
    "    trigrams = ngrams(text.split(), n=3, left_pad_symbol='<s>', right_pad_symbol='</s>')\n",
    "    p = 1.0\n",
    "    for trigram in trigrams:\n",
    "        p *= calc_trigram_proba(trigram)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no , i mean training set error where it is written . the training error is the number of misclassified examples in the training set divided by training set size . similarly test set error is number of misclassified examples in test set divided by training set size . also you may want to check coursera machine learning class , especially videos for advice for applying machine learning . those advice are quite relevant to your situation .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.45363538246843e-288"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train.sample(1).text.values[0]\n",
    "print(text)\n",
    "\n",
    "calc_text_proba(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perplexity(text):\n",
    "    trigrams = list(ngrams(text.split(), n=3, left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
    "    pp = 1.0\n",
    "    for trigram in trigrams:\n",
    "        pp *= (1 / calc_trigram_proba(trigram))** (1/len(trigrams)) \n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am predicting the binary class , ie if it is in top or not , of a security based upon it is performance using predictors from current time . so it is simply a cross sectional classifier . as of now i have used random forest and neural net for this purpose . now i want to extend it so that i can one step ahead prediction of the class . please suggest some starting point . i understand it might be open ended question . thanks for reading . i know how to use time series , but i am not sure how to go so for a classifier . also all the predictors are numeric variables , none of them are categorical . i am doing all in r , so it would be great if i get related pointers , not a strict constraint though .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2068.6367285395027"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train.sample(1).text.values[0]\n",
    "print(text)\n",
    "\n",
    "calc_perplexity(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93af03fc1ca14fce927e70e8a7a23c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=718864.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4033762010.4495244"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(calc_perplexity(text) for text in tqdm(train.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
